{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce51459f7f8e4530b569a44b92dcd954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Load model in 8-bit quantization (for RTX 4080 Super)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "# Load model fully into GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute token validity mask (only run once)\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "all_tokens = torch.arange(vocab_size, device=\"cuda\")  # Tensor of token IDs\n",
    "decoded_tokens = tokenizer.batch_decode(all_tokens.unsqueeze(1))  # Vectorized decoding\n",
    "\n",
    "# Create boolean mask **directly as a tensor** (avoids Python list overhead)\n",
    "valid_mask = torch.tensor(\n",
    "    [token.isalpha() and len(token) > 1 for token in decoded_tokens], dtype=torch.bool, device=\"cuda\"\n",
    ").clone()  # `clone()` avoids PyTorch memory issues\n",
    "\n",
    "# Save valid token IDs & decoded token texts\n",
    "allowed_tokens = torch.masked_select(all_tokens, valid_mask)  # Fast retrieval during inference\n",
    "allowed_token_texts = tokenizer.batch_decode(allowed_tokens.tolist())  # Decode only once\n",
    "\n",
    "# Preallocate masked logits tensor for reuse\n",
    "masked_logits = torch.empty(vocab_size, dtype=torch.float16, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_inference(prompt):\n",
    "    inference_prompt = \"Based on this financial report my investment advice is to\"\n",
    "    new_prompt = prompt + inference_prompt\n",
    "\n",
    "    # Tokenize input & move to GPU\n",
    "    inputs = tokenizer(new_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract logits for next token (FAST)\n",
    "    logits = outputs.logits[:, -1, :].squeeze()  # Shape: (vocab_size,)\n",
    "\n",
    "    # Reset and mask logits (FAST IN-PLACE)\n",
    "    masked_logits.fill_(-float(\"inf\"))  # Reset all values in-place\n",
    "    masked_logits[valid_mask] = logits[valid_mask]  # Keep only valid tokens\n",
    "\n",
    "    # Compute probabilities\n",
    "    probs = torch.nn.functional.softmax(masked_logits, dim=-1)\n",
    "\n",
    "    # Get corresponding probabilities for allowed tokens\n",
    "    allowed_probs = torch.masked_select(probs, valid_mask)\n",
    "\n",
    "    # Create dictionary without CPU transfer overhead\n",
    "    token_prob_dict = dict(zip(allowed_token_texts, allowed_probs.tolist()))\n",
    "\n",
    "    # Sort & return top 10 words\n",
    "    return dict(sorted(token_prob_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "token_prob_dict = fast_inference(\"Explain quantum mechanics in simple terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_report = \"\"\"\n",
    "NexaTech Inc. - Q1 2024 Financial Report\n",
    "For the period ended March 31, 2024\n",
    "\n",
    "NexaTech Inc. is pleased to report strong financial results for the first quarter of 2024, driven by robust revenue growth, margin expansion, and continued execution of strategic initiatives.\n",
    "\n",
    "Financial Performance\n",
    "For the quarter ended March 31, 2024, total revenue increased 18.4% year-over-year to $1.74 billion, reflecting higher demand across core product segments and continued market penetration in key geographies. Gross profit expanded 22.7% to $764 million, driven by pricing optimization and supply chain efficiencies. Gross margin improved to 43.9%, compared to 41.6% in the prior year.\n",
    "\n",
    "Operating income increased 27.2% to $498 million, representing an operating margin of 28.6%, up from 26.3% in Q1 2023. Net income attributable to shareholders was $382 million, a 30.1% increase over the prior-year period, translating to diluted earnings per share (EPS) of $2.74, compared to $2.08 in Q1 2023.\n",
    "\n",
    "Strategic and Operational Highlights\n",
    "During the quarter, NexaTech successfully launched its AI-driven enterprise cloud platform, achieving widespread adoption among Fortune 500 clients. The company also expanded its international presence, securing strategic partnerships in Europe and Asia-Pacific, further diversifying its revenue streams.\n",
    "\n",
    "Capital expenditures for Q1 totaled $112 million, reflecting continued investment in AI and cloud infrastructure. The company maintained a strong balance sheet, with $2.1 billion in cash and short-term investments and a net debt-to-equity ratio of 0.24, ensuring ample liquidity to fund future growth.\n",
    "\n",
    "Outlook\n",
    "Given the strong performance in Q1 and continued market momentum, NexaTech is raising full-year 2024 guidance, expecting revenue growth of 15%â€“18%, with an EPS range of $10.50â€“$11.20, up from previous guidance of $9.80â€“$10.50.\n",
    "\n",
    "The company remains committed to operational efficiency, technological innovation, and shareholder value creation, positioning itself for sustained growth in a dynamic market environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_report = \"\"\"\n",
    "CoreSteel Industries - Q1 2024 Financial Report\n",
    "For the period ended March 31, 2024\n",
    "\n",
    "CoreSteel Industries reports a challenging first quarter, as macroeconomic headwinds, supply chain disruptions, and weaker-than-expected demand weighed on financial results. The company remains focused on cost management and operational efficiency while navigating ongoing market volatility.\n",
    "\n",
    "Financial Performance\n",
    "For the quarter ended March 31, 2024, revenue declined 8.7% year-over-year to $640 million, primarily due to reduced order volumes and pricing pressures in the steel manufacturing segment. Gross profit decreased 11.2% to $172 million, with gross margin contracting to 26.9%, down from 29.3% in Q1 2023, reflecting higher raw material costs.\n",
    "\n",
    "Operating income declined 22.8% to $74 million, with operating margin falling to 11.6%, compared to 14.2% in the prior-year period. Net income attributable to shareholders was $41 million, representing a 29.4% year-over-year decrease, leading to diluted earnings per share (EPS) of $0.88, compared to $1.23 in Q1 2023.\n",
    "\n",
    "Operational Challenges and Cost Management\n",
    "CoreSteel experienced weaker demand in North America and Europe, where key customers delayed capital investments amid economic uncertainty. Additionally, higher energy and labor costs pressured margins. The company initiated a cost-reduction program targeting $50 million in annualized savings, including workforce optimization and supply chain restructuring.\n",
    "\n",
    "Capital expenditures in Q1 were $52 million, primarily allocated to equipment upgrades and digitalization initiatives. CoreSteel ended the quarter with $284 million in cash and equivalents, maintaining financial flexibility, although net debt increased to $1.18 billion, raising leverage concerns.\n",
    "\n",
    "Outlook\n",
    "Given the uncertain economic environment, CoreSteel adjusts its full-year 2024 guidance, now anticipating revenue contraction of 4%â€“6%, with EPS expected between $3.00â€“$3.40, down from prior estimates of $3.80â€“$4.20. The company remains focused on cost containment, operational efficiency, and supply chain resilience while assessing opportunities for strategic realignment.\n",
    "\n",
    "While near-term headwinds persist, CoreSteel continues to leverage its strong industry position and long-term customer relationships to drive stability and recovery.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Next Token Prediction Probabilities (Only Meaningful Words):**\n",
      "sell       | Probability: 0.3723\n",
      "buy        | Probability: 0.1144\n",
      "avoid      | Probability: 0.0516\n",
      "stay       | Probability: 0.0372\n",
      "remain     | Probability: 0.0259\n",
      "maintain   | Probability: 0.0109\n",
      "invest     | Probability: 0.0086\n",
      "proceed    | Probability: 0.0083\n",
      "consider   | Probability: 0.0046\n",
      "recommend  | Probability: 0.0032\n",
      "caut       | Probability: 0.0031\n",
      "carefully  | Probability: 0.0026\n",
      "Buy        | Probability: 0.0022\n",
      "purchase   | Probability: 0.0020\n",
      "closely    | Probability: 0.0017\n",
      "caution    | Probability: 0.0017\n",
      "approach   | Probability: 0.0017\n",
      "Hold       | Probability: 0.0016\n",
      "adopt      | Probability: 0.0012\n",
      "exercise   | Probability: 0.0011\n",
      "re         | Probability: 0.0011\n",
      "Invest     | Probability: 0.0009\n",
      "analyze    | Probability: 0.0009\n",
      "divers     | Probability: 0.0009\n",
      "investors  | Probability: 0.0008\n",
      "evaluate   | Probability: 0.0008\n",
      "advise     | Probability: 0.0007\n",
      "BU         | Probability: 0.0006\n",
      "minimize   | Probability: 0.0006\n",
      "ste        | Probability: 0.0006\n",
      "Avoid      | Probability: 0.0006\n",
      "decrease   | Probability: 0.0005\n",
      "Stay       | Probability: 0.0005\n",
      "refr       | Probability: 0.0005\n",
      "strongly   | Probability: 0.0005\n",
      "div        | Probability: 0.0004\n",
      "either     | Probability: 0.0004\n",
      "retain     | Probability: 0.0004\n",
      "further    | Probability: 0.0003\n",
      "provide    | Probability: 0.0003\n",
      "view       | Probability: 0.0003\n",
      "still      | Probability: 0.0003\n",
      "Wait       | Probability: 0.0003\n",
      "ST         | Probability: 0.0003\n",
      "investigate | Probability: 0.0003\n",
      "increase   | Probability: 0.0002\n",
      "temporarily | Probability: 0.0002\n",
      "moderate   | Probability: 0.0002\n",
      "prior      | Probability: 0.0002\n",
      "buying     | Probability: 0.0002\n"
     ]
    }
   ],
   "source": [
    "token_prob_dict = fast_inference(bad_report)\n",
    "# Step 7: Sort and display top predictions\n",
    "sorted_token_probs = {k: v for k, v in sorted(token_prob_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(\"\\nðŸ”¹ **Next Token Prediction Probabilities (Only Meaningful Words):**\")\n",
    "for token, prob in list(sorted_token_probs.items())[:50]:  \n",
    "    print(f\"{token:<10} | Probability: {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnrpred_with_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
